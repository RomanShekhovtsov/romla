{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "df = pd.DataFrame(np.random.randn(10,3))\n",
    "df = df.applymap(lambda x: round(x*10,0))\n",
    "\n",
    "#np.random.randn(10,3)\n",
    "\n",
    "df.iloc[3:5,0] = np.nan\n",
    "df.iloc[4:6,1] = np.nan\n",
    "df.iloc[5:8,2] = np.nan\n",
    "df.info()\n",
    "sys.getsizeof(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "file_name = r'..\\check_8_c\\train.csv'\n",
    "df = pd.read_csv(file_name, nrows=100, low_memory=False )\n",
    "df_X = df.drop('target', axis=1)\n",
    "number_columns = [\n",
    "    col_name\n",
    "    for col_name in df_X.columns\n",
    "    if col_name.startswith('number')\n",
    "]\n",
    "df_X = df_X[number_columns]\n",
    "df_X.fillna(-1, inplace=True)\n",
    "\n",
    "pca = PCA()\n",
    "pca\n",
    "#pca.fit_transform(df_X)\n",
    "#expl_var[ expl_var > max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_var_ratio = pca.explained_variance_ratio_\n",
    "i = 0\n",
    "sum_ratio = 0\n",
    "for x in expl_var_ratio:\n",
    "    sum_ratio +=x\n",
    "    i += 1\n",
    "    if sum_ratio >.99:\n",
    "        break\n",
    "print(i)\n",
    "np.sum(expl_var_ratio[:i])\n",
    "len(pca.components_[0])\n",
    "#expl_var = pca.explained_variance_\n",
    "#max_expl_var = max(expl_var)\n",
    "#expl_var[ expl_var > max_expl_var * 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "a = {'a':1, 'b':2}\n",
    "\n",
    "import os\n",
    "d = pd.DataFrame([a])\n",
    "header = not os.path.isfile('metrics.csv')\n",
    "d.to_csv('metrics.csv', mode='a', index=False,header=header )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "r = LogisticRegression()\n",
    "r.predict()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_name = r'C:\\ds\\sdsj\\check_8_c\\train.csv'\n",
    "file_size = os.path.getsize(file_name)\n",
    "\n",
    "\"\"\"\n",
    "df = pd.read_csv(file_name, nrows=100 )\n",
    "df.to_csv('test_row_size.csv', header=False)\n",
    "row_size = os.path.getsize('test_row_size.csv')\n",
    "print('rows estimation', file_size/row_size)\n",
    "\n",
    "usecols=['number_0','wefwefwewe']\n",
    "usecols = df.columns & usecols\n",
    "print(usecols)\n",
    "\"\"\"\n",
    "\n",
    "#df = pd.read_csv(file_name, usecols=usecols, nrows=1000 )\n",
    "df = pd.read_csv(file_name, nrows=1000 )\n",
    "#corr = df[ :df.shape[1] ].corr()\n",
    "#df_corr = pd.DataFrame( corr )\n",
    "\n",
    "#corr_cols = set()\n",
    "#for i in range(df_corr.shape[0]):\n",
    "#    row = df_corr.iloc[i]    \n",
    "#    print(row[row>0.95])\n",
    "\n",
    "    #cols = row.filter(lambda x: abs(x) > 0.95)\n",
    "#        if abs(v) > hyper_params_corr_limit and i != j:\n",
    "#            corr_cols[corr.columns[j]] = True            \n",
    "\n",
    "print(corr_cols)\n",
    "\n",
    "#df = pd.read_csv(r'C:\\ds\\sdsj\\check_8_c\\train.csv', nrows=10 )\n",
    "#df.shape\n",
    "#round(1234,-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "#df.fillna\n",
    "\n",
    "df_X = df.copy()\n",
    "df_X[2].value_counts().index[0]\n",
    "\n",
    "#df_X[1].fillna( df_X[1].max(), inplace=True)\n",
    "#df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "argv = ['--train-csv', r'..\\check_1_r\\train.csv',\n",
    "       '--model-dir', r'.',\n",
    "       '--mode', 'regression']\n",
    "print(' '.join(argv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "argv = ['--test-csv', r'..\\check_1_r\\test.csv',\n",
    "        '--prediction-csv', r'..\\check_1_r\\prediction.csv', \n",
    "       '--model-dir', r'.']\n",
    "print(' '.join(argv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score\n",
    "argv = ['--test-target-csv', r'..\\check_1_r\\test-target.csv',\n",
    "       '--prediction-csv', r'..\\check_1_r\\h2o_prediction.csv']\n",
    "print(' '.join(argv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "#from tpot import TPOTClassifier, TPOTRegressor\n",
    "#tpotr = TPOTRegressor()\n",
    "df = pd.read_csv(r'..\\check_8_c\\train.csv', nrows=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#if any(df.isnull()):    \n",
    "#   df.fillna(-1, inplace=True)\n",
    "\n",
    "print(df.isnull().values.any())\n",
    "df.fillna(-1, inplace=True)\n",
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def transform_ds(df):\n",
    "    int_cols = []\n",
    "    float_cols = []\n",
    "    category_cols = []\n",
    "    other_cols = []\n",
    "    \n",
    "    df_onehot = pd.DataFrame()\n",
    "\n",
    "    for col_name in df.columns:\n",
    "        \n",
    "        n_uniq = df[col_name].nunique()\n",
    "        if n_uniq == 1: # skip constant columns            \n",
    "            continue\n",
    "            \n",
    "        col_type = df.dtypes[col_name]\n",
    "        if col_type in ['int','int64']:\n",
    "            int_cols.append(col_name)\n",
    "        elif col_type in ['float', 'float64']:\n",
    "            float_cols.append(col_name)\n",
    "        elif col_type == 'object':\n",
    "            uniq_values = df[col_name].unique()\n",
    "            total = len( df[col_name] )\n",
    "            if 2 < n_uniq <= 20:\n",
    "                for uniq in uniq_values:\n",
    "                    df_onehot['onehot_{}={}'.format(col_name,uniq)] = (df[col_name] == uniq).astype(int)\n",
    "            elif n_uniq / total < 0.5: \n",
    "                category_cols.append(col_name)\n",
    "            else:\n",
    "                other_cols.append(col_name)\n",
    "        else:\n",
    "            other_cols.append(col_name)\n",
    "\n",
    "    df_opt = df_onehot.apply(pd.to_numeric, downcast='integer')\n",
    "    \n",
    "    if len(int_cols) > 0:\n",
    "        df_opt[int_cols] =  df[int_cols].apply(pd.to_numeric, downcast='integer')\n",
    "    \n",
    "    if len(float_cols) > 0:\n",
    "        df_opt[float_cols] = df[float_cols].apply(pd.to_numeric, downcast='float')\n",
    "        \n",
    "    if len(category_cols) > 0:\n",
    "        df_opt[category_cols] = df[category_cols].astype('category')    \n",
    "        \n",
    "    if len(other_cols) > 0:\n",
    "        df_opt[other_cols] = df[other_cols]\n",
    "\n",
    "    return df_opt\n",
    "\n",
    "df_opt = transform_ds(df)\n",
    "df_opt.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold # mutual_info_regression\n",
    "fs = VarianceThreshold(0.001)\n",
    "df_nums = df_opt.select_dtypes(include=['float32','int8']) \n",
    "fs.fit(df_nums) # fit_transform(df)\n",
    "\n",
    "supported = fs.get_support()\n",
    "print('rows to remove:', len(supported[supported==False]))\n",
    "#print( df_opt['number_6'].value_counts() )\n",
    "for i in range(len(supported)):\n",
    "    if not supported[i]:\n",
    "        print(df_opt.columns[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "df_X =df_nums.drop('target',axis=1)\n",
    "df_y = df.target\n",
    "mir = mutual_info_regression(df_X[:1000], df_y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(mir)\n",
    "#print(len(mir[mir>0.02]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_X.columns[mir>np.mean(mir) + 4*np.std(mir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_columns = [\n",
    "        col_name\n",
    "         for col_name in df_opt.columns\n",
    "         if df_opt[col_name].nunique() == 1\n",
    "        ]\n",
    "constant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_opt.isnull().values.any())\n",
    "\n",
    "#df.fillna(-1, inplace=True)\n",
    "#print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "import datetime\n",
    "\n",
    "\n",
    "empty_date = datetime.datetime.strptime('0001-01-01', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "def parse_dt(x):\n",
    "    if not isinstance(x, str):\n",
    "        return empty_date\n",
    "    elif len(x) == len('2010-01-01'):\n",
    "        return datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "    elif len(x) == len('2010-01-01 10:10:10'):\n",
    "        return datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    else:\n",
    "        return empty_date\n",
    "    \n",
    "\n",
    "def transform_datetime_features(df):\n",
    "    datetime_columns = [\n",
    "        col_name\n",
    "        for col_name in df.columns\n",
    "        if col_name.startswith('datetime')\n",
    "    ]\n",
    "\n",
    "    df_date = pd.DataFrame() #(dtypes=[['datetime','uint8','uint8','uint8','uint16']])\n",
    "    for col_name in datetime_columns:\n",
    "        #df_date[col_name],\n",
    "        #df_date['number_weekday_{}'.format(col_name)],\n",
    "        #df_date['number_month_{}'.format(col_name)],\n",
    "        #df_date['number_day_{}'.format(col_name)],\n",
    "        #df_date['number_hour_{}'.format(col_name)],\n",
    "        #df_date['number_hour_of_week_{}'.format(col_name)],\n",
    "        #df_date['number_minute_of_day_{}'.format(col_name)] = \n",
    "        df[col_name].apply(lambda x: parse_dt(x)[0] )\n",
    "        \n",
    "        #df_date[col_name] = a[0]\n",
    "        #df_date['number_weekday_{}'.format(col_name)] = df_date[col_name].apply(lambda x: x.weekday())\n",
    "        #df_date['number_month_{}'.format(col_name)] = df_date[col_name].apply(lambda x: x.month)\n",
    "        #df_date['number_day_{}'.format(col_name)] = df_date[col_name].apply(lambda x: x.day)\n",
    "        #f_date['number_hour_{}'.format(col_name)] = df_date[col_name].apply(lambda x: x.hour)\n",
    "        #df_date['number_hour_of_week_{}'.format(col_name)] = df_date[col_name].apply(lambda x: x.hour + x.weekday() * 24)\n",
    "        #df_date['number_minute_of_day_{}'.format(col_name)] = df_date[col_name].apply(lambda x: x.minute + x.hour * 60)        \n",
    "        \n",
    "    return transform_ds(df_date)\n",
    "\n",
    "\"\"\"\n",
    "apply(lambda x: parse_dt(x)) (FAST):\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 143525 entries, 0 to 143524\n",
    "Columns: 427 entries, number_weekday_datetime_0 to datetime_90\n",
    "dtypes: datetime64[ns](90), float32(337)\n",
    "memory usage: 283.1 MB\n",
    "Wall time: 6min 16s\n",
    "\n",
    "pd.to_datetime (SLOW):\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 143525 entries, 0 to 143524\n",
    "Columns: 630 entries, number_weekday_datetime_0 to datetime_90\n",
    "dtypes: datetime64[ns](90), int16(174), int8(366)\n",
    "memory usage: 196.3 MB\n",
    "Wall time: 8min 34s\n",
    "\"\"\"\n",
    "\n",
    "#df_dates = transform_datetime_features(df_opt)\n",
    "#df_dates.info(memory_usage='deep')\n",
    "str(datetime.MINYEAR).rjust(4,'0')\n",
    "str(20183).rjust(4,'0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_opt['datetime_3']\n",
    "#d = pd.DataFrame(dtype=[['datetime','uint8','uint8','uint8','uint8','uint8','uint16']])\n",
    "#type(df_opt['datetime_0'])\n",
    "#pd.Series((None,None,None,None,None,None,None))\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt[df_dates.columns] = df_dates\n",
    "df_opt.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dates = transform_ds(pd.DataFrame())\n",
    "#df_dates.info(memory_usage='deep')\n",
    "#df_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt.info(memory_usage='deep')\n",
    "df_opt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_int = df.select_dtypes(include=['int','int64'])\n",
    "df_opt = df_int.apply(pd.to_numeric, downcast='unsigned')\n",
    "print(df_opt.shape)\n",
    "print(df_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float = df.select_dtypes(include=['float'])\n",
    "df_opt = pd.concat( [df_opt, df_float.apply(pd.to_numeric, downcast='float')], axis=1)\n",
    "print(df_opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(df.dtypes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_rows( file_name ):\n",
    "    nrows = 200\n",
    "    test_file_name = 'test_row_count.csv'\n",
    "\n",
    "    file_size = os.path.getsize(file_name)\n",
    "    df = pd.read_csv(file_name, nrows=nrows)\n",
    "    df.to_csv(test_file_name, header=False)\n",
    "    row_size = os.path.getsize(test_file_name) / nrows\n",
    "    rows = file_size / row_size\n",
    "    size = rows * sys.getsizeof(df) / nrows\n",
    "    return { 'rows': int(rows), 'row_size': int(row_size), 'total_size': int(size) }\n",
    "\n",
    "#estimate_rows(r'..\\check_1_r\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "reg = GradientBoostingRegressor()\n",
    "cls = GradientBoostingClassifier()\n",
    "print( reg.get_params().keys() )\n",
    "print()\n",
    "print( cls.get_params().keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#?GridSearchCV\n",
    "?GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "msg = MIMEText('test')\n",
    "msg['Subject'] = 'subj'\n",
    "msg['From'] = 'pomka@yandex.ru'\n",
    "msg['To'] = 'pomka@yandex.ru'\n",
    "\n",
    "HOST = \"smtp.yandex.ru\"\n",
    "server = smtplib.SMTP(HOST)\n",
    "\n",
    "username = 'pomka'\n",
    "server.starttls()\n",
    "server.login(username, input())\n",
    "server.sendmail(msg['From'], msg['To'], msg.as_string())\n",
    "server.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = rnd_cols.copy()\n",
    "data_cols.append('zero')\n",
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA()\n",
    "#pca.fit_transform(df)\n",
    "#pca.explained_variance_ratio_\n",
    "from sklearn.feature_selection import VarianceThreshold # mutual_info_regression\n",
    "fs = VarianceThreshold(0.001)\n",
    "a2 = fs.fit_transform(df[data_cols])\n",
    "print(len(fs.variances_))\n",
    "print(a2.shape)\n",
    "#print( df.columns )\n",
    "#GOOD:\n",
    "#mir = mutual_info_regression(df[rnd_cols], df['multi']) !\n",
    "#print(mir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rows = 10**4\n",
    "cols = 100\n",
    "a = np.random.randn(rows, cols)\n",
    "rnd_cols = list(map( str, range(1,cols+1) ))\n",
    "#print(rnd_cols)\n",
    "df = pd.DataFrame(a, columns=rnd_cols)\n",
    "\n",
    "#.corr()\n",
    "df['depend'] = (df['1']+df['2']) / (df['3'] * df['4'])\n",
    "df['zero'] = np.zeros(rows)\n",
    "#df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "mir = mutual_info_regression(df[rnd_cols], df['depend'])\n",
    "print(mir)\n",
    "plt.plot(mir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[rnd_cols].columns[mir>np.mean(mir)]) # + 1*np.std(mir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mir[mir > 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_unique = df_opt.apply(lambda x: x.nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.sort_values('counts', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_unique[df_unique > 2]\n",
    "df_unique = df_unique[df_unique <= 20]\n",
    "df_unique.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique['number_597']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=[0.6,0.4,0.58,0.1,-1130]\n",
    "m=['a','b','c','d','e']\n",
    "#sorted_scores = sorted(scores)[::-1]\n",
    "#[x for x in X if x>np.mean(X)]\n",
    "m[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'..\\check_1_r\\train.csv', nrows=None, low_memory=False)\n",
    "constant_columns = [\n",
    "        col_name\n",
    "        for col_name in df.columns\n",
    "        if df[col_name].nunique() == 1\n",
    "    ]\n",
    "constant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from zipfile import ZipFile\n",
    "folder = '003-no-ext-libs\\\\'\n",
    "#%cd $folder\n",
    "zip_file_name = folder + time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime()) + '_submission.zip'\n",
    "    \n",
    "files = [\n",
    "    'metadata.json',\n",
    "    'predict.py',\n",
    "    'train.py',\n",
    "    'utils.py']\n",
    "\n",
    "with ZipFile(zip_file_name, mode='w') as submission:\n",
    "    for file in files:\n",
    "        submission.write(folder + file,arcname=file)\n",
    "submission.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =  pd.read_csv(r'..\\check_3_r\\train.csv')\n",
    "if any(df.isnull()):\n",
    "    df.fillna(-1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))\n",
    "for n in range(100,1000,100):\n",
    "    df_X = df[:n]\n",
    "    df_unique = df_X.apply(lambda x: x.nunique())\n",
    "    df_const = df_unique[df_unique == 1]\n",
    "\n",
    "    print(n, len(df_X.columns) - len(df_const))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "try:\n",
    "    raise Exception('ALL FEATURES DROPPED, STOPPING')\n",
    "except BaseException as e:\n",
    "    print(e)\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "est = GradientBoostingClassifier()\n",
    "type(est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "columns = b'dwefwefwefwe'\n",
    "hash_digest = hashlib.md5(columns).hexdigest()\n",
    "print(hash_digest.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "!SET OMP_NUM_THREADS=4\n",
    "size = 10000\n",
    "a = np.random.random_sample((size, size))\n",
    "b = np.random.random_sample((size, size))\n",
    "n = np.dot(a,b)\n",
    "#np.show_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
