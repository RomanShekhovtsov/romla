Submission evaluation log
Dataset check_1 (success)
Train time: 0:00:03.842725
Prediction time: 0:00:02.772012
Train stdout/stderr:
-------------------
2018-09-30 22:18:04 read dataset (shape: (365, 42), nrows: None) [0.01 sec]
2018-09-30 22:18:04 impute missing values [0.0 sec]
2018-09-30 22:18:05 optimize dataframe (144279 to 51934, ratio: 2.78) [0.05 sec]
2018-09-30 22:18:05 features from datetime (7 columns) [0.02 sec]
2018-09-30 22:18:05 missing dates values [0.0 sec]
2018-09-30 22:18:05 optimize dataframe (20544 to 5579, ratio: 3.68) [0.01 sec]
2018-09-30 22:18:05 calculate unique values [0.07 sec]
2018-09-30 22:18:05 categorical encoding (33 columns) [0.04 sec]
2018-09-30 22:18:05 optimize dataframe (96464 to 12149, ratio: 7.94) [0.04 sec]
2018-09-30 22:18:05 used columns: 76, size: 39159
2018-09-30 22:18:05 scaling (df_X size: 222032 ) [0.0 sec]
2018-09-30 22:18:05 Starting models selection by sampling data by (5000, 10000, 15000) rows
/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:616: DataConversionWarning: Data with input dtype int8, int16, float32 were all converted to float64 by StandardScaler.
  return self.partial_fit(X, y)
/opt/conda/lib/python3.6/site-packages/sklearn/base.py:459: DataConversionWarning: Data with input dtype int8, int16, float32 were all converted to float64 by StandardScaler.
  return self.fit(X, **fit_params).transform(X)
2018-09-30 22:18:05 cross validation 365 rows (score:5.4934707269274465) [0.18 sec]
2018-09-30 22:18:05 GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, n_iter_no_change=None, presort='auto',
             random_state=None, subsample=1.0, tol=0.0001,
             validation_fraction=0.1, verbose=0, warm_start=False)
2018-09-30 22:18:05 cross validation 365 rows (score:5.889858285470288) [0.18 sec]
2018-09-30 22:18:05 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:05 cross validation 365 rows (score:5.6806797069159005) [0.19 sec]
2018-09-30 22:18:05 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,
          max_features='auto', max_leaf_nodes=None,
          min_impurity_decrease=0.0, min_impurity_split=None,
          min_samples_leaf=1, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
          oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:05 cross validation 365 rows (score:7.277721225133338) [0.18 sec]
2018-09-30 22:18:05 AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
         n_estimators=50, random_state=None)
2018-09-30 22:18:05 Sample size meet dataset size, stop sampling
2018-09-30 22:18:06 fit best model GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, n_iter_no_change=None, presort='auto',
             random_state=None, subsample=1.0, tol=0.0001,
             validation_fraction=0.1, verbose=0, warm_start=False) [0.08 sec]
2018-09-30 22:18:06 Train time: 1.0654115676879883
2018-09-30 22:18:06 --------------------------------------------------------------------------------

-------------------
Prediction stdout/stderr:
-------------------
predict.py:77: DataConversionWarning: Data with input dtype int8, int16, float32 were all converted to float64 by StandardScaler.
  X_scaled = model_config['scaler'].transform(df)
2018-09-30 22:18:09 read dataset (shape: (172, 41), nrows: None) [0.01 sec]
2018-09-30 22:18:09 impute missing values [0.0 sec]
2018-09-30 22:18:09 optimize dataframe (66668 to 23840, ratio: 2.8) [0.05 sec]
2018-09-30 22:18:09 features from datetime (7 columns) [0.01 sec]
2018-09-30 22:18:09 missing dates values [0.0 sec]
2018-09-30 22:18:09 optimize dataframe (9736 to 2684, ratio: 3.63) [0.01 sec]
2018-09-30 22:18:09 categorical encoding (33 columns) [0.04 sec]
2018-09-30 22:18:09 optimize dataframe (45512 to 5780, ratio: 7.87) [0.04 sec]
2018-09-30 22:18:09 scale [0.0 sec]
2018-09-30 22:18:09 predict [0.0 sec]
2018-09-30 22:18:09 save prediction [0.11 sec]
2018-09-30 22:18:09 Prediction time: 0.533698320388794

-------------------

Dataset check_2 (success)
Train time: 0:00:08.444941
Prediction time: 0:00:02.792077
Train stdout/stderr:
-------------------
/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:616: DataConversionWarning: Data with input dtype int8, float32 were all converted to float64 by StandardScaler.
  return self.partial_fit(X, y)
/opt/conda/lib/python3.6/site-packages/sklearn/base.py:459: DataConversionWarning: Data with input dtype int8, float32 were all converted to float64 by StandardScaler.
  return self.fit(X, **fit_params).transform(X)
2018-09-30 22:18:12 read dataset (shape: (13958, 11), nrows: None) [0.02 sec]
2018-09-30 22:18:12 impute missing values [0.0 sec]
2018-09-30 22:18:12 optimize dataframe (3316502 to 420722, ratio: 7.88) [0.03 sec]
2018-09-30 22:18:12 features from datetime (0 columns) [0.0 sec]
2018-09-30 22:18:12 missing dates values [0.0 sec]
2018-09-30 22:18:12 optimize dataframe (24 to 24, ratio: 1.0) [0.0 sec]
2018-09-30 22:18:12 calculate unique values [0.01 sec]
2018-09-30 22:18:12 categorical encoding (14 columns) [0.02 sec]
2018-09-30 22:18:12 optimize dataframe (1563400 to 195516, ratio: 8.0) [0.03 sec]
2018-09-30 22:18:12 used columns: 20, size: 488634
2018-09-30 22:18:12 scaling (df_X size: 2233392 ) [0.01 sec]
2018-09-30 22:18:12 Starting models selection by sampling data by (5000, 10000, 15000) rows
2018-09-30 22:18:12 cross validation 5000 rows (score:1.2856656705913823) [0.57 sec]
2018-09-30 22:18:12 GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, n_iter_no_change=None, presort='auto',
             random_state=None, subsample=1.0, tol=0.0001,
             validation_fraction=0.1, verbose=0, warm_start=False)
2018-09-30 22:18:13 cross validation 5000 rows (score:1.243296354190892) [0.38 sec]
2018-09-30 22:18:13 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:13 cross validation 5000 rows (score:1.2407282921441047) [0.28 sec]
2018-09-30 22:18:13 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,
          max_features='auto', max_leaf_nodes=None,
          min_impurity_decrease=0.0, min_impurity_split=None,
          min_samples_leaf=1, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
          oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:14 cross validation 5000 rows (score:2.0403878021460606) [0.48 sec]
2018-09-30 22:18:14 AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
         n_estimators=50, random_state=None)
2018-09-30 22:18:14 Survive 3 models
2018-09-30 22:18:15 cross validation 10000 rows (score:1.2834492501822894) [0.98 sec]
2018-09-30 22:18:15 GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, n_iter_no_change=None, presort='auto',
             random_state=None, subsample=1.0, tol=0.0001,
             validation_fraction=0.1, verbose=0, warm_start=False)
2018-09-30 22:18:15 cross validation 10000 rows (score:1.1032460873700498) [0.69 sec]
2018-09-30 22:18:15 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:16 cross validation 10000 rows (score:1.0963353902721409) [0.48 sec]
2018-09-30 22:18:16 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,
          max_features='auto', max_leaf_nodes=None,
          min_impurity_decrease=0.0, min_impurity_split=None,
          min_samples_leaf=1, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
          oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:16 Survive 2 models
2018-09-30 22:18:17 cross validation 13958 rows (score:1.0311073668458017) [0.88 sec]
2018-09-30 22:18:17 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:17 cross validation 13958 rows (score:1.0205895754666818) [0.58 sec]
2018-09-30 22:18:17 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,
          max_features='auto', max_leaf_nodes=None,
          min_impurity_decrease=0.0, min_impurity_split=None,
          min_samples_leaf=1, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
          oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:17 Sample size meet dataset size, stop sampling
2018-09-30 22:18:18 fit best model ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,
          max_features='auto', max_leaf_nodes=None,
          min_impurity_decrease=0.0, min_impurity_split=None,
          min_samples_leaf=1, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
          oob_score=False, random_state=None, verbose=0, warm_start=False) [0.37 sec]
2018-09-30 22:18:18 Train time: 5.822789669036865
2018-09-30 22:18:18 --------------------------------------------------------------------------------

-------------------
Prediction stdout/stderr:
-------------------
predict.py:77: DataConversionWarning: Data with input dtype int8, float32 were all converted to float64 by StandardScaler.
  X_scaled = model_config['scaler'].transform(df)
2018-09-30 22:18:21 read dataset (shape: (5976, 10), nrows: None) [0.01 sec]
2018-09-30 22:18:21 impute missing values [0.0 sec]
2018-09-30 22:18:21 optimize dataframe (1372381 to 157358, ratio: 8.72) [0.03 sec]
2018-09-30 22:18:21 features from datetime (0 columns) [0.0 sec]
2018-09-30 22:18:21 missing dates values [0.0 sec]
2018-09-30 22:18:21 optimize dataframe (24 to 24, ratio: 1.0) [0.0 sec]
2018-09-30 22:18:21 categorical encoding (14 columns) [0.01 sec]
2018-09-30 22:18:21 optimize dataframe (669416 to 83768, ratio: 7.99) [0.02 sec]
2018-09-30 22:18:21 scale [0.0 sec]
2018-09-30 22:18:21 predict [0.04 sec]
2018-09-30 22:18:21 save prediction [0.13 sec]
2018-09-30 22:18:21 Prediction time: 0.5290732383728027

-------------------

Dataset check_3 (success)
Train time: 0:01:02.441516
Prediction time: 0:00:04.677439
Train stdout/stderr:
-------------------
/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:616: DataConversionWarning: Data with input dtype int8, int16, float32 were all converted to float64 by StandardScaler.
  return self.partial_fit(X, y)
/opt/conda/lib/python3.6/site-packages/sklearn/base.py:459: DataConversionWarning: Data with input dtype int8, int16, float32 were all converted to float64 by StandardScaler.
  return self.fit(X, **fit_params).transform(X)
2018-09-30 22:18:25 read dataset (shape: (250000, 43), nrows: None) [1.25 sec]
2018-09-30 22:18:25 impute missing values [0.04 sec]
2018-09-30 22:18:25 optimize dataframe (100750104 to 18812459, ratio: 5.36) [0.3 sec]
2018-09-30 22:18:25 features from datetime (7 columns) [0.1 sec]
2018-09-30 22:18:25 missing dates values [0.0 sec]
2018-09-30 22:18:26 optimize dataframe (12525584 to 2275584, ratio: 5.5) [0.07 sec]
2018-09-30 22:18:26 calculate unique values [0.11 sec]
2018-09-30 22:18:26 categorical encoding (26 columns) [0.07 sec]
2018-09-30 22:18:26 optimize dataframe (52000104 to 6500104, ratio: 8.0) [0.21 sec]
2018-09-30 22:18:26 used columns: 69, size: 23500104
2018-09-30 22:18:27 scaling (df_X size: 138000112 ) [0.55 sec]
2018-09-30 22:18:27 Starting models selection by sampling data by (5000, 10000, 15000) rows
2018-09-30 22:18:27 cross validation 5000 rows (score:71136.19864621686) [0.7 sec]
2018-09-30 22:18:27 GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, n_iter_no_change=None, presort='auto',
             random_state=None, subsample=1.0, tol=0.0001,
             validation_fraction=0.1, verbose=0, warm_start=False)
2018-09-30 22:18:28 cross validation 5000 rows (score:70858.44886642181) [0.39 sec]
2018-09-30 22:18:28 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:28 cross validation 5000 rows (score:73978.64393810013) [0.39 sec]
2018-09-30 22:18:28 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,
          max_features='auto', max_leaf_nodes=None,
          min_impurity_decrease=0.0, min_impurity_split=None,
          min_samples_leaf=1, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
          oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:28 cross validation 5000 rows (score:102036.95510661101) [0.39 sec]
2018-09-30 22:18:28 AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
         n_estimators=50, random_state=None)
2018-09-30 22:18:28 Survive 3 models
2018-09-30 22:18:30 cross validation 10000 rows (score:86806.06744772723) [1.39 sec]
2018-09-30 22:18:30 GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, n_iter_no_change=None, presort='auto',
             random_state=None, subsample=1.0, tol=0.0001,
             validation_fraction=0.1, verbose=0, warm_start=False)
2018-09-30 22:18:30 cross validation 10000 rows (score:90925.21489257329) [0.69 sec]
2018-09-30 22:18:30 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:31 cross validation 10000 rows (score:90440.26958189238) [0.59 sec]
2018-09-30 22:18:31 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,
          max_features='auto', max_leaf_nodes=None,
          min_impurity_decrease=0.0, min_impurity_split=None,
          min_samples_leaf=1, min_samples_split=2,
          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
          oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:18:31 Only one model survive, stop sampling
2018-09-30 22:19:23 fit best model GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, n_iter_no_change=None, presort='auto',
             random_state=None, subsample=1.0, tol=0.0001,
             validation_fraction=0.1, verbose=0, warm_start=False) [52.1 sec]
2018-09-30 22:19:23 Train time: 59.4157338142395
2018-09-30 22:19:23 --------------------------------------------------------------------------------

-------------------
Prediction stdout/stderr:
-------------------
predict.py:77: DataConversionWarning: Data with input dtype int8, int16, float32 were all converted to float64 by StandardScaler.
  X_scaled = model_config['scaler'].transform(df)
2018-09-30 22:19:27 read dataset (shape: (146400, 42), nrows: None) [0.58 sec]
2018-09-30 22:19:27 impute missing values [0.01 sec]
2018-09-30 22:19:27 optimize dataframe (57828104 to 10429266, ratio: 5.54) [0.19 sec]
2018-09-30 22:19:27 features from datetime (7 columns) [0.04 sec]
2018-09-30 22:19:27 missing dates values [0.0 sec]
2018-09-30 22:19:28 optimize dataframe (7333272 to 1330872, ratio: 5.51) [0.04 sec]
2018-09-30 22:19:28 categorical encoding (26 columns) [0.06 sec]
2018-09-30 22:19:28 optimize dataframe (30451304 to 3806504, ratio: 8.0) [0.15 sec]
2018-09-30 22:19:28 scale [0.1 sec]
2018-09-30 22:19:28 predict [0.3 sec]
2018-09-30 22:19:29 save prediction [0.63 sec]
2018-09-30 22:19:29 Prediction time: 2.4023630619049072

-------------------

Dataset check_4 (success)
Train time: 0:03:38.406149
Prediction time: 0:00:05.625223
Train stdout/stderr:
-------------------
/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:616: DataConversionWarning: Data with input dtype int8, int16, float32, int32 were all converted to float64 by StandardScaler.
  return self.partial_fit(X, y)
/opt/conda/lib/python3.6/site-packages/sklearn/base.py:459: DataConversionWarning: Data with input dtype int8, int16, float32, int32 were all converted to float64 by StandardScaler.
  return self.fit(X, **fit_params).transform(X)
2018-09-30 22:19:36 read dataset (shape: (114130, 143), nrows: None) [4.15 sec]
2018-09-30 22:19:36 impute missing values [0.08 sec]
2018-09-30 22:19:37 optimize dataframe (150765834 to 64338341, ratio: 2.34) [0.39 sec]
2018-09-30 22:19:37 features from datetime (21 columns) [0.09 sec]
2018-09-30 22:19:37 missing dates values [0.0 sec]
2018-09-30 22:19:37 optimize dataframe (17156572 to 3118582, ratio: 5.5) [0.09 sec]
2018-09-30 22:19:37 calculate unique values [0.44 sec]
2018-09-30 22:19:38 categorical encoding (193 columns) [0.46 sec]
2018-09-30 22:19:39 optimize dataframe (176216824 to 22027194, ratio: 8.0) [0.87 sec]
2018-09-30 22:19:39 used columns: 293, size: 63912904
2018-09-30 22:19:40 scaling (df_X size: 112 ) [1.03 sec]
2018-09-30 22:19:40 Starting models selection by sampling data by (5000, 10000, 15000) rows
2018-09-30 22:19:46 cross validation 5000 rows (score:0.9537170414229411) [6.0 sec]
2018-09-30 22:19:46 GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
2018-09-30 22:19:46 cross validation 5000 rows (score:0.8022882689662291) [0.5 sec]
2018-09-30 22:19:46 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
2018-09-30 22:19:47 cross validation 5000 rows (score:0.818941281169076) [0.4 sec]
2018-09-30 22:19:47 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:19:49 cross validation 5000 rows (score:0.877362787296915) [2.4 sec]
2018-09-30 22:19:49 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
2018-09-30 22:19:49 Survive 2 models
2018-09-30 22:20:03 cross validation 10000 rows (score:0.9755356677140948) [14.05 sec]
2018-09-30 22:20:03 GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
2018-09-30 22:20:08 cross validation 10000 rows (score:0.8930729602929784) [5.0 sec]
2018-09-30 22:20:08 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
2018-09-30 22:20:08 Only one model survive, stop sampling
2018-09-30 22:23:08 fit best model GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False) [179.51 sec]
2018-09-30 22:23:08 Train time: 215.65888953208923
2018-09-30 22:23:08 --------------------------------------------------------------------------------

-------------------
Prediction stdout/stderr:
-------------------
predict.py:77: DataConversionWarning: Data with input dtype int8, int16, float32, int32 were all converted to float64 by StandardScaler.
  X_scaled = model_config['scaler'].transform(df)
2018-09-30 22:23:12 read dataset (shape: (45385, 142), nrows: None) [1.36 sec]
2018-09-30 22:23:12 impute missing values [0.02 sec]
2018-09-30 22:23:12 optimize dataframe (59590609 to 25589387, ratio: 2.33) [0.25 sec]
2018-09-30 22:23:12 features from datetime (21 columns) [0.05 sec]
2018-09-30 22:23:12 missing dates values [0.0 sec]
2018-09-30 22:23:12 optimize dataframe (6844806 to 1262451, ratio: 5.42) [0.05 sec]
2018-09-30 22:23:13 categorical encoding (193 columns) [0.32 sec]
2018-09-30 22:23:13 optimize dataframe (70074544 to 8759409, ratio: 8.0) [0.48 sec]
2018-09-30 22:23:13 scale [0.12 sec]
2018-09-30 22:23:14 predict [0.19 sec]
2018-09-30 22:23:14 save prediction [0.2 sec]
2018-09-30 22:23:14 Prediction time: 3.368881940841675

-------------------

Dataset check_5 (success)
Train time: 0:02:53.534560
Prediction time: 0:00:05.663217
Train stdout/stderr:
-------------------
/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:616: DataConversionWarning: Data with input dtype int8, int16, float32, int32 were all converted to float64 by StandardScaler.
  return self.partial_fit(X, y)
/opt/conda/lib/python3.6/site-packages/sklearn/base.py:459: DataConversionWarning: Data with input dtype int8, int16, float32, int32 were all converted to float64 by StandardScaler.
  return self.fit(X, **fit_params).transform(X)
2018-09-30 22:23:18 read dataset (shape: (467485, 17), nrows: None) [1.23 sec]
2018-09-30 22:23:18 impute missing values [0.03 sec]
2018-09-30 22:23:18 optimize dataframe (91159679 to 23400339, ratio: 3.9) [0.26 sec]
2018-09-30 22:23:18 features from datetime (7 columns) [0.08 sec]
2018-09-30 22:23:18 missing dates values [0.0 sec]
2018-09-30 22:23:18 optimize dataframe (23386474 to 4219589, ratio: 5.54) [0.1 sec]
2018-09-30 22:23:19 calculate unique values [0.12 sec]
2018-09-30 22:23:19 categorical encoding (72 columns) [0.36 sec]
2018-09-30 22:23:20 optimize dataframe (269271464 to 33659024, ratio: 8.0) [1.08 sec]
2018-09-30 22:23:20 used columns: 90, size: 56098304
2018-09-30 22:23:21 scaling (df_X size: 112 ) [1.31 sec]
2018-09-30 22:23:21 Starting models selection by sampling data by (5000, 10000, 15000) rows
2018-09-30 22:23:23 cross validation 5000 rows (score:0.7723609593626392) [1.58 sec]
2018-09-30 22:23:23 GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
2018-09-30 22:23:23 cross validation 5000 rows (score:0.7203066228082892) [0.29 sec]
2018-09-30 22:23:23 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
2018-09-30 22:23:24 cross validation 5000 rows (score:0.713885204411194) [0.29 sec]
2018-09-30 22:23:24 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
2018-09-30 22:23:24 cross validation 5000 rows (score:0.7648194618629375) [0.59 sec]
2018-09-30 22:23:24 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
2018-09-30 22:23:24 Survive 2 models
2018-09-30 22:23:27 cross validation 10000 rows (score:0.7721544255292166) [3.0 sec]
2018-09-30 22:23:27 GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
2018-09-30 22:23:28 cross validation 10000 rows (score:0.766532789326568) [0.99 sec]
2018-09-30 22:23:28 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
2018-09-30 22:23:28 Only one model survive, stop sampling
2018-09-30 22:26:07 fit best model GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=None,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False) [159.0 sec]
2018-09-30 22:26:07 Train time: 170.4910500049591
2018-09-30 22:26:07 --------------------------------------------------------------------------------

-------------------
Prediction stdout/stderr:
-------------------
predict.py:77: DataConversionWarning: Data with input dtype int8, int16, float32, int32 were all converted to float64 by StandardScaler.
  X_scaled = model_config['scaler'].transform(df)
2018-09-30 22:26:11 read dataset (shape: (169638, 16), nrows: None) [0.42 sec]
2018-09-30 22:26:11 impute missing values [0.01 sec]
2018-09-30 22:26:11 optimize dataframe (31722410 to 8338351, ratio: 3.8) [0.11 sec]
2018-09-30 22:26:11 features from datetime (7 columns) [0.04 sec]
2018-09-30 22:26:11 missing dates values [0.0 sec]
2018-09-30 22:26:11 optimize dataframe (8494124 to 1538966, ratio: 5.52) [0.05 sec]
2018-09-30 22:26:11 categorical encoding (72 columns) [0.16 sec]
2018-09-30 22:26:12 optimize dataframe (97711592 to 12214040, ratio: 8.0) [0.46 sec]
2018-09-30 22:26:12 scale [0.13 sec]
2018-09-30 22:26:13 predict [0.58 sec]
2018-09-30 22:26:13 save prediction [0.54 sec]
2018-09-30 22:26:13 Prediction time: 2.7987775802612305

-------------------

Dataset public_1 (success)
Train time: 0:00:03.481788
Prediction time: 0:00:02.720364

Dataset public_2 (success)
Train time: 0:00:44.474758
Prediction time: 0:00:03.669429

Dataset public_3 (success)
Train time: 0:01:02.568581
Prediction time: 0:00:05.637369

Dataset public_4 (error: prediction file not exists)
Train time: 0:00:03.376327
Prediction time: 0:00:02.662153

Dataset public_5 (success)
Train time: 0:01:57.574530
Prediction time: 0:00:04.642021

Dataset public_6 (success)
Train time: 0:03:38.526658
Prediction time: 0:00:05.629607

Dataset public_7 (error: train timed out)
Train time: 0:30:00.834473

Dataset public_8 (error: prediction file not exists)
Train time: 0:01:50.399154
Prediction time: 0:00:02.539536