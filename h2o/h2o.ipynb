{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def parse_dt(x):\n",
    "    if not isinstance(x, str):\n",
    "        return None\n",
    "    elif len(x) == len('2010-01-01'):\n",
    "        return datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "    elif len(x) == len('2010-01-01 10:10:10'):\n",
    "        return datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def transform_datetime_features(df):\n",
    "    datetime_columns = [\n",
    "        col_name\n",
    "        for col_name in df.columns\n",
    "        if col_name.startswith('datetime')\n",
    "    ]\n",
    "    for col_name in datetime_columns:\n",
    "        df[col_name] = df[col_name].apply(lambda x: parse_dt(x))\n",
    "        df['number_weekday_{}'.format(col_name)] = df[col_name].apply(lambda x: x.weekday())\n",
    "        df['number_month_{}'.format(col_name)] = df[col_name].apply(lambda x: x.month)\n",
    "        df['number_day_{}'.format(col_name)] = df[col_name].apply(lambda x: x.day)\n",
    "        df['number_hour_{}'.format(col_name)] = df[col_name].apply(lambda x: x.hour)\n",
    "        df['number_hour_of_week_{}'.format(col_name)] = df[col_name].apply(lambda x: x.hour + x.weekday() * 24)\n",
    "        df['number_minute_of_day_{}'.format(col_name)] = df[col_name].apply(lambda x: x.minute + x.hour * 60)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# use this to stop the algorithm before time limit exceeds\n",
    "TIME_LIMIT = int(os.environ.get('TIME_LIMIT', 5*60))\n",
    "\n",
    "ONEHOT_MAX_UNIQUE_VALUES = 20\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-csv', type=argparse.FileType('r'), required=True)\n",
    "    parser.add_argument('--model-dir', required=True)\n",
    "    parser.add_argument('--mode', choices=['classification', 'regression'], required=True)\n",
    "    \n",
    "    argv = ['--train-csv', r'..\\check_1_r\\train.csv',\n",
    "           '--model-dir', r'.',\n",
    "           '--mode', 'regression']\n",
    "    args = parser.parse_args(argv)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    df = pd.read_csv(args.train_csv)\n",
    "    df_y = df.target\n",
    "    df_X = df.drop('target', axis=1)\n",
    "\n",
    "    print('Dataset read, shape {}'.format(df_X.shape))\n",
    "\n",
    "    # dict with data necessary to make predictions\n",
    "    model_config = {}\n",
    "\n",
    "    # features from datetime\n",
    "    df_X = transform_datetime_features(df_X)\n",
    "\n",
    "    # missing values\n",
    "    if any(df_X.isnull()):\n",
    "        model_config['missing'] = True\n",
    "        df_X.fillna(-1, inplace=True)\n",
    "\n",
    "    # categorical encoding\n",
    "    categorical_values = {}\n",
    "    for col_name in list(df_X.columns):\n",
    "        col_unique_values = df_X[col_name].unique()\n",
    "        if 2 < len(col_unique_values) <= ONEHOT_MAX_UNIQUE_VALUES:\n",
    "            categorical_values[col_name] = col_unique_values\n",
    "            for unique_value in col_unique_values:\n",
    "                df_X['onehot_{}={}'.format(col_name, unique_value)] = (df_X[col_name] == unique_value).astype(int)\n",
    "    model_config['categorical_values'] = categorical_values\n",
    "\n",
    "    # drop constant features\n",
    "    constant_columns = [\n",
    "        col_name\n",
    "        for col_name in df_X.columns\n",
    "        if df_X[col_name].nunique() == 1\n",
    "        ]\n",
    "    df_X.drop(constant_columns, axis=1, inplace=True)\n",
    "\n",
    "    # use only numeric columns\n",
    "    used_columns = [\n",
    "        col_name\n",
    "        for col_name in df_X.columns\n",
    "        if col_name.startswith('number') or col_name.startswith('onehot')\n",
    "        ]\n",
    "    df_X = df_X[used_columns]\n",
    "    model_config['used_columns'] = used_columns\n",
    "\n",
    "    # scaling\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df_X)\n",
    "    model_config['scaler'] = scaler\n",
    "\n",
    "    # fitting\n",
    "    model_config['mode'] = args.mode\n",
    "    if args.mode == 'regression':\n",
    "        model = Ridge()\n",
    "    else:\n",
    "        model = LogisticRegression()\n",
    "\n",
    "    model.fit(df_scaled, df_y)\n",
    "    model_config['model'] = model\n",
    "\n",
    "    model_config_filename = os.path.join(args.model_dir, 'model_config.pkl')\n",
    "    with open(model_config_filename, 'wb') as fout:\n",
    "        pickle.dump(model_config, fout, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print('Train time: {}'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset read, shape (172, 41)\n",
      "Prediction time: 0.06550836563110352\n"
     ]
    }
   ],
   "source": [
    "# use this to stop the algorithm before time limit exceeds\n",
    "TIME_LIMIT = int(os.environ.get('TIME_LIMIT', 5*60))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test-csv', type=argparse.FileType('r'), required=True)\n",
    "    parser.add_argument('--prediction-csv', type=argparse.FileType('w'), required=True)\n",
    "    parser.add_argument('--model-dir', required=True)\n",
    "\n",
    "    argv = ['--test-csv', r'..\\check_1_r\\test.csv',\n",
    "            '--prediction-csv', r'..\\check_1_r\\prediction.csv', \n",
    "           '--model-dir', r'.']\n",
    "    args = parser.parse_args(argv)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # load model\n",
    "    model_config_filename = os.path.join(args.model_dir, 'model_config.pkl')\n",
    "    with open(model_config_filename, 'rb') as fin:\n",
    "        model_config = pickle.load(fin)\n",
    "\n",
    "    # read dataset\n",
    "    df = pd.read_csv(args.test_csv)\n",
    "    print('Dataset read, shape {}'.format(df.shape))\n",
    "\n",
    "    # features from datetime\n",
    "    df = transform_datetime_features(df)\n",
    "\n",
    "    # missing values\n",
    "    if model_config['missing']:\n",
    "        df.fillna(-1, inplace=True)\n",
    "    elif any(df.isnull()):\n",
    "        df.fillna(value=df.mean(axis=0), inplace=True)\n",
    "\n",
    "    # categorical encoding\n",
    "    for col_name, unique_values in model_config['categorical_values'].items():\n",
    "        for unique_value in unique_values:\n",
    "            df['onehot_{}={}'.format(col_name, unique_value)] = (df[col_name] == unique_value).astype(int)\n",
    "\n",
    "    # filter columns\n",
    "    used_columns = model_config['used_columns']\n",
    "    df_used = df[used_columns]\n",
    "    # scale\n",
    "    X_scaled = model_config['scaler'].transform(df_used)\n",
    "\n",
    "    model = model_config['model']\n",
    "    if model_config['mode'] == 'regression':\n",
    "        df['prediction'] = model.predict(X_scaled)\n",
    "    elif model_config['mode'] == 'classification':\n",
    "        df['prediction'] = model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "    prediction = df[['line_id', 'prediction']]\n",
    "    prediction.to_csv(args.prediction_csv, index=False)\n",
    "\n",
    "    print('Prediction time: {}'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22.187721041236983\n",
      "Scoring time: 0.0175020694732666\n"
     ]
    }
   ],
   "source": [
    "#scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test-target-csv', type=argparse.FileType('r'), required=True)\n",
    "    parser.add_argument('--prediction-csv', type=argparse.FileType('r'), required=True)\n",
    "\n",
    "    argv = ['--test-target-csv', r'..\\check_1_r\\test-target.csv',\n",
    "           '--prediction-csv', r'..\\check_1_r\\h2o_prediction.csv']\n",
    "    args = parser.parse_args(argv)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    test_target = pd.read_csv(args.test_target_csv)\n",
    "    prediction =  pd.read_csv(args.prediction_csv)\n",
    "    \n",
    "    rmse = mean_squared_error(test_target, prediction) ** 0.5\n",
    "    print( 'RMSE:',rmse )\n",
    "    print('Scoring time: {}'.format(time.time() - start_time))    \n",
    "# baseline RMSE: RMSE: 8.095668993508879\n",
    "# h2o AutoML RMSE: RMSE: 10.339605784611129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>18 hours 22 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>4 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_SBT_Shekhovtsov_RV_txmoqq</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.295 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------\n",
       "H2O cluster uptime:         18 hours 22 mins\n",
       "H2O cluster timezone:       Europe/Moscow\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.8\n",
       "H2O cluster version age:    4 days\n",
       "H2O cluster name:           H2O_from_python_SBT_Shekhovtsov_RV_txmoqq\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.295 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  -----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h2o = df_X\n",
    "df_h2o['target'] = df_y\n",
    "#df_h2o_scaled = scaler.fit_transform(df_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\p\\anaconda3\\lib\\site-packages\\h2o\\utils\\shared_utils.py:177: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  data = _handle_python_lists(python_obj.as_matrix().tolist(), -1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train = h2o.H2OFrame(df_h2o)\n",
    "test = h2o.H2OFrame(df_used)\n",
    "x = train.columns\n",
    "y = \"target\"\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train = train.scale()\n",
    "test = test.scale()\n",
    "aml = H2OAutoML(max_runtime_secs = 30)\n",
    "aml.train(x = x, y = y,\n",
    "          training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                             </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">     mae</th><th style=\"text-align: right;\">  rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_0_AutoML_20180926_121705_model_0            </td><td style=\"text-align: right;\">                0.128208</td><td style=\"text-align: right;\">0.358061</td><td style=\"text-align: right;\">0.128208</td><td style=\"text-align: right;\">0.201276</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_0_AutoML_20180926_121705</td><td style=\"text-align: right;\">                0.13061 </td><td style=\"text-align: right;\">0.361399</td><td style=\"text-align: right;\">0.13061 </td><td style=\"text-align: right;\">0.207824</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_0_AutoML_20180926_121705   </td><td style=\"text-align: right;\">                0.133861</td><td style=\"text-align: right;\">0.365871</td><td style=\"text-align: right;\">0.133861</td><td style=\"text-align: right;\">0.206093</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>XRT_0_AutoML_20180926_121705                         </td><td style=\"text-align: right;\">                0.139417</td><td style=\"text-align: right;\">0.373386</td><td style=\"text-align: right;\">0.139417</td><td style=\"text-align: right;\">0.199515</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180926_121705_model_8            </td><td style=\"text-align: right;\">                0.141649</td><td style=\"text-align: right;\">0.376363</td><td style=\"text-align: right;\">0.141649</td><td style=\"text-align: right;\">0.212985</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>DRF_0_AutoML_20180926_121705                         </td><td style=\"text-align: right;\">                0.143858</td><td style=\"text-align: right;\">0.379286</td><td style=\"text-align: right;\">0.143858</td><td style=\"text-align: right;\">0.208757</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180926_121705_model_7            </td><td style=\"text-align: right;\">                0.146123</td><td style=\"text-align: right;\">0.38226 </td><td style=\"text-align: right;\">0.146123</td><td style=\"text-align: right;\">0.250417</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>GLM_grid_0_AutoML_20180926_121705_model_0            </td><td style=\"text-align: right;\">                0.147317</td><td style=\"text-align: right;\">0.383819</td><td style=\"text-align: right;\">0.147317</td><td style=\"text-align: right;\">0.234308</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180926_121705_model_16           </td><td style=\"text-align: right;\">                0.152451</td><td style=\"text-align: right;\">0.390449</td><td style=\"text-align: right;\">0.152451</td><td style=\"text-align: right;\">0.205333</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180926_121705_model_17           </td><td style=\"text-align: right;\">                0.154075</td><td style=\"text-align: right;\">0.392524</td><td style=\"text-align: right;\">0.154075</td><td style=\"text-align: right;\">0.213365</td><td style=\"text-align: right;\">    nan</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds = aml.leader.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_list = pd.DataFrame()\n",
    "output_list['line_id'] = df['line_id']\n",
    "output_list['prediction'] = preds.as_data_frame()['predict']\n",
    "#df.index.delete\n",
    "output_list.to_csv(r\"..\\check_1_r\\h2o_prediction.csv\", index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     line_id\n",
       "0          0\n",
       "1          2\n",
       "2          6\n",
       "3         10\n",
       "4         13\n",
       "5         14\n",
       "6         15\n",
       "7         21\n",
       "8         33\n",
       "9         38\n",
       "10        40\n",
       "11        43\n",
       "12        46\n",
       "13        52\n",
       "14        53\n",
       "15        55\n",
       "16        57\n",
       "17        59\n",
       "18        64\n",
       "19        67\n",
       "20        68\n",
       "21        69\n",
       "22        71\n",
       "23        74\n",
       "24        85\n",
       "25        87\n",
       "26        88\n",
       "27        89\n",
       "28        93\n",
       "29        96\n",
       "..       ...\n",
       "142      418\n",
       "143      426\n",
       "144      429\n",
       "145      430\n",
       "146      438\n",
       "147      442\n",
       "148      451\n",
       "149      452\n",
       "150      454\n",
       "151      460\n",
       "152      462\n",
       "153      474\n",
       "154      476\n",
       "155      479\n",
       "156      480\n",
       "157      483\n",
       "158      484\n",
       "159      488\n",
       "160      489\n",
       "161      491\n",
       "162      503\n",
       "163      509\n",
       "164      510\n",
       "165      513\n",
       "166      514\n",
       "167      519\n",
       "168      520\n",
       "169      529\n",
       "170      533\n",
       "171      536\n",
       "\n",
       "[172 rows x 1 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output_list['prediction'] = preds.as_data_frame()\n",
    "#output_list.head()\n",
    "output_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
